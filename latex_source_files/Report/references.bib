@article{borkarbertsekas,
  author    = {Jinane Abounadi and
               Dimitri P. Bertsekas and
               Vivek S. Borkar},
  title     = {Learning Algorithms for Markov Decision Processes with Average Cost},
  journal   = {{SIAM} J. Control. Optim.},
  volume    = {40},
  number    = {3},
  pages     = {681--698},
  year      = {2001},
  url       = {https://doi.org/10.1137/S0363012999361974},
  doi       = {10.1137/S0363012999361974},
  timestamp = {Thu, 09 Jul 2020 22:39:56 +0200},
  biburl    = {https://dblp.org/rec/journals/siamco/AbounadiBB01.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{avrachenkov2021whittle,
      title={Whittle index based Q-learning for restless bandits with average reward}, 
      author={Konstantin E. Avrachenkov and Vivek S. Borkar},
      year={2021},
      eprint={2004.14427},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@book{dp2,
author = {Bertsekas, Dimitri P.},
title = {Dynamic Programming and Optimal Control, Vol. II},
year = {2012},
isbn = {1886529434},
publisher = {Athena Scientific},
edition = {4th}
}

@book{dp1,
author = {Bertsekas, Dimitri P.},
title = {Dynamic Programming and Optimal Control, Vol. 1},
year = {2005},
isbn = {1886529264},
publisher = {Athena Scientific},
edition = {3rd}
}


@book{borkarbook,
author = {Vivek S. Borkar },
title = {Stochastic Approximation
A Dynamical Systems Viewpoint},
year = {2008},
isbn = {978-81-85931-85-2},
publisher = {Hindustan Book Agency, Gurgaon
},
edition = {1st}
}
@misc{avrachenkov2021gradient,
      title={Full Gradient DQN Reinforcement Learning: A Provably Convergent Scheme}, 
      author={K. E. Avrachenkov and V. S. Borkar and H. P. Dolhare and K. Patil},
      year={2021},
      eprint={2103.05981},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{Mahadevan2005AverageRR,
  title={Average Reward Reinforcement Learning: Foundations, Algorithms, and Empirical Results},
  author={Sridhar Mahadevan},
  journal={Machine Learning},
  year={2005},
  volume={22},
  pages={159-195}
}
@misc{dewanto2021averagereward,
      title={Average-reward model-free reinforcement learning: a systematic review and literature mapping}, 
      author={Vektor Dewanto and George Dunn and Ali Eshragh and Marcus Gallagher and Fred Roosta},
      year={2021},
      eprint={2010.08920},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inbook{whittleindices,
publisher = {John Wiley & Sons, Ltd},
isbn = {9780470980033},
title = {Restless Bandits and Lagrangian Relaxation},
booktitle = {Multi‚ÄêArmed Bandit Allocation Indices},
chapter = {6},
pages = {149-172},
doi = {https://doi.org/10.1002/9780470980033.ch6},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470980033.ch6},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470980033.ch6},
year = {2011}
}


@misc{markovmit,
      title={{Finite-State Markov Chains MIT OCW Chapter 3}},
      author={Robert Gallager},
      year={2011},
      primaryClass={cs.LG}
}

@misc{mdpsilver,
      title={{Lecture 2: Markov Decision Processes, UCL Course on RL}},
      author={David Silver},
      year={2015},
      primaryClass={cs.LG}
}

@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  url = {http://dx.doi.org/10.1038/nature14236},
  volume = 518,
  year = 2015
}
@article{DBLP:journals/corr/HasseltGS15,
  author    = {Hado van Hasselt and
               Arthur Guez and
               David Silver},
  title     = {Deep Reinforcement Learning with Double Q-learning},
  journal   = {CoRR},
  volume    = {abs/1509.06461},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.06461},
  eprinttype = {arXiv},
  eprint    = {1509.06461},
  timestamp = {Mon, 13 Aug 2018 16:47:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HasseltGS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{whittlepaper,
 ISSN = {00219002},
 URL = {http://www.jstor.org/stable/3214163},
 abstract = {We consider a population of n projects which in general continue to evolve whether in operation or not (although by different rules). It is desired to choose the projects in operation at each instant of time so as to maximise the expected rate of reward, under a constraint upon the expected number of projects in operation. The Lagrange multiplier associated with this constraint defines an index which reduces to the Gittins index when projects not being operated are static. If one is constrained to operate m projects exactly then arguments are advanced to support the conjecture that, for m and n large in constant ratio, the policy of operating the m projects of largest current index is nearly optimal. The index is evaluated for some particular projects.},
 author = {P. Whittle},
 journal = {Journal of Applied Probability},
 pages = {287--298},
 publisher = {Applied Probability Trust},
 title = {Restless Bandits: Activity Allocation in a Changing World},
 volume = {25},
 year = {1988}
}
@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{openaigym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01540},
  eprinttype = {arXiv},
  eprint    = {1606.01540},
  timestamp = {Fri, 08 Nov 2019 12:51:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/BrockmanCPSSTZ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{openspiel,
  author    = {Marc Lanctot and
               Edward Lockhart and
               Jean{-}Baptiste Lespiau and
               Vin{\'{\i}}cius Flores Zambaldi and
               Satyaki Upadhyay and
               Julien P{\'{e}}rolat and
               Sriram Srinivasan and
               Finbarr Timbers and
               Karl Tuyls and
               Shayegan Omidshafiei and
               Daniel Hennes and
               Dustin Morrill and
               Paul Muller and
               Timo Ewalds and
               Ryan Faulkner and
               J{\'{a}}nos Kram{\'{a}}r and
               Bart De Vylder and
               Brennan Saeta and
               James Bradbury and
               David Ding and
               Sebastian Borgeaud and
               Matthew Lai and
               Julian Schrittwieser and
               Thomas W. Anthony and
               Edward Hughes and
               Ivo Danihelka and
               Jonah Ryan{-}Davis},
  title     = {OpenSpiel: {A} Framework for Reinforcement Learning in Games},
  journal   = {CoRR},
  volume    = {abs/1908.09453},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.09453},
  eprinttype = {arXiv},
  eprint    = {1908.09453},
  timestamp = {Fri, 09 Oct 2020 09:46:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-09453.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{tasfi2016PLE,
  author = {Tasfi, Norman},
  title = {PyGame Learning Environment},
  year = {2016},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/ntasfi/PyGame-Learning-Environment}}
}

@misc{highway-env,
  author = {Leurent, Edouard},
  title = {An Environment for Autonomous Driving Decision-Making},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/eleurent/highway-env}},
}
@misc{stable-baselines3,
  author = {Raffin, Antonin and Hill, Ashley and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Dormann, Noah},
  title = {Stable Baselines3},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/stable-baselines3}},
}

@INPROCEEDINGS{circulantdynamics,  author={Fu, Jing and Nazarathy, Yoni and Moka, Sarat and Taylor, Peter G.},  booktitle={2019 Australian   New Zealand Control Conference (ANZCC)},   title={Towards Q-learning the Whittle Index for Restless Bandits},   year={2019},  volume={},  number={}, pages={249-254},  doi={10.1109/ANZCC47194.2019.8945748}}

@article{survey,
  author    = {Vektor Dewanto and
               George Dunn and
               Ali Eshragh and
               Marcus Gallagher and
               Fred Roosta},
  title     = {Average-reward model-free reinforcement learning: a systematic review
               and literature mapping},
  journal   = {CoRR},
  volume    = {abs/2010.08920},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.08920},
  eprinttype = {arXiv},
  eprint    = {2010.08920},
  timestamp = {Wed, 21 Oct 2020 12:11:48 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-08920.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}